# projects section data
# If you don't have language feature(language.yml is empty), ignore "i18n" items
# Suggest projects' img be located at '/static/assets/img/landing', and edit following img items.
- name: ReFiNe
  # website:
  img: /images/refine.png
  desc: My project proposal for the MSCA Postdoctoral Fellowship "ReFiNe - Redefining Field robot deployment through Neuro-symbolic visual sensemaking" has received the EU Seal of Excellence (SoE). Currently funded by Politecnico di Milano through the SoE Fellowship, this project investigates how to assess the trustworthiness of Vision Language models in complex scenarios that require advanced visual capabilities through the use of graph knowledge representations. 
 
- name: AgrifoodTEF
  website: https://www.agrifoodtef.eu/
  img: /images/TEFlogo.jpeg
  desc: I have contributed to AgrifoodTEF, a 60M euro EU funded initiative (2023-2028) involving partners from 9 EU countries aimed at providing the first  EU-wide Testing and Experimentation Facility for the AI and Robotics solutions in Precision Agriculture such as autonomous weeding, harvesting, and precise plant spraying. 
 

- name: L'Oréal-UNESCO Program
  website: https://www.forwomeninscience.com/
  img: /images/lorealunesco-logo.png
  desc: Awardee of the L'Oréal-UNESCO for Women in Science Fellowship to conduct research on visually intelligent robotic applications for precision agriculture. 

- name: GATEKEEPER 
  website: https://www.gatekeeper-project.eu/
  img: /images/GK-logo.png
  desc: I have contributed to the EU flagship project GATEKEEPER, which has focused on developing smart digital technologies to support health independent living for the ageing population. In this context, I have developed robot vision and semantic mapping solutions to retrieve personal items in home environments as an assistive tool in cases of mild  cognitive and visual impairment. 

- name: Visually Intelligent Agents (VIA) 
  website: http://robots.kmi.open.ac.uk/ 
  img: /images/HanS.png
  desc: My PhD research has been focused on enhancing the Visual Intelligence of service robots by combining Knowledge-driven technologies with Machine Learning. Specifically, I have developed a prototype of robot assistant which can monitor office environments in search for potentially dangerous situations (e.g., flammable items left by ignition sources, cluttered emergency exits, dangling cables, and others). 

- name: SPICE 
  website: https://spice-h2020.eu/
  img: /images/spice-logo.png
  desc: I have contributed to the EU-funded project SPICE (Social cohesion, participation, and Inclusion through Cultural Engagement), where I have explored the use of Deep Learning and Neurosymbolic Learning methods to classify artistic subjects from cultural heritage image collections. 

- name: The 2019 SciRoc Challenge   
  img: /images/sciroc-logo.png
  desc: I have been part of the organising team of the 1st Smart Cities and Robotics Challenge (SciRoc), which was held in Milton Keynes (UK) on September 2019. This was the first robotic challenge to be held in a public shopping mall, to explore the integration of robots within Smart City infrastructures.    

- name: The Human Screenome Project 
  website: http://screenomics.stanford.edu/  
  img: /images/screenome.PNG
  desc: While working in Prof. Lee Giles’ Lab at PSU, I have been a part of the Human Screenome project, a collaboration between Penn State University and Stanford University. I have been in charge of implementing an  end-to-end architecture for extracting and indexing textual information from smartphone and laptop screenshots. This platform has allowed researchers in the behavioural and medical  sciences to analyse how daily media consumption may affect fragile user categories, such as adolescents and low-income groups. Outcomes from this research have been featured in The New  York Times, SAGE Ocean, and Medium, among others.
 
